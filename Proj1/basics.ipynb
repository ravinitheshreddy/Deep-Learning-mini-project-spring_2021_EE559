{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "# Prologue\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "N = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train_input sample as Ints:\n",
      " tensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   9,  57, 106,  54,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,  35, 226, 186, 123, 186, 156,   2,   0,   0,   0,   0],\n",
      "         [  0,   0,   0, 156, 132,   0,   0,   4, 197,  21,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,  86, 233, 132,  74, 132, 244,  37,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,  41, 130, 155, 140, 211,  91,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   4, 195,  40,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,  26, 251,  11,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0, 101, 184,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0, 211, 151,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   4, 239,  97,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   2,  93,   3,   0,   0,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0, 116, 227, 240, 227, 209, 122,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0, 140, 140, 140, 140, 227, 252,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,  12, 190, 165,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,  19, 193, 227,  40,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,  44, 224, 209,  15,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,  56, 252,  84,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0, 253,  84,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0, 125, 246,  40,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,  62, 165, 246,  75,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,  12, 212, 223, 165,  46,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print('Example train_input sample as Ints:\\n', train_input[0].int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input: torch.Size([1000, 2, 14, 14])\n",
      "Train target: torch.Size([1000])\n",
      "Train classes: torch.Size([1000, 2])\n",
      "... Same for test too\n",
      "\n",
      "Possible values of train_target: tensor([0, 1])\n",
      "Pairs of classes for all samples:\n",
      " tensor([[9, 3],\n",
      "        [5, 4],\n",
      "        [7, 4],\n",
      "        ...,\n",
      "        [1, 4],\n",
      "        [3, 5],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Reference\n",
    "print('Train input:', train_input.size())\n",
    "print('Train target:', train_target.size())\n",
    "print('Train classes:', train_classes.size())\n",
    "print('... Same for test too\\n')\n",
    "# Target = 1 if digit1<= digit2\n",
    "print('Possible values of train_target:', train_target.unique())\n",
    "print('Pairs of classes for all samples:\\n', train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "# def train_model(model, train_input, train_target, train_classes, mini_batch_size, nb_epochs = 100, criterion = nn.MSELoss(), optimizer = None):\n",
    "#     eta = 1e-1\n",
    "#     #\n",
    "#     for e in range(nb_epochs):\n",
    "#         acc_loss = 0\n",
    "#         # We do this with mini-batches\n",
    "#         for b in range(0, train_input.size(0), mini_batch_size):\n",
    "#             #### Modify this based on model outputs ###########\n",
    "#             output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "#             loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "#             ###################################################\n",
    "#             #acc_loss = acc_loss + loss.item()\n",
    "#             #\n",
    "#             model.zero_grad()\n",
    "#             loss.backward()\n",
    "#             #\n",
    "#             if (optimizer is None):\n",
    "#                 with torch.no_grad():\n",
    "#                     for p in model.parameters():\n",
    "#                         p -= eta * p.grad\n",
    "#             else:\n",
    "#                 optimizer.step()\n",
    "#         #\n",
    "#         print(e, acc_loss)\n",
    "    \n",
    "# def compute_nb_errors(model, test_input, test_target, test_classes, mini_batch_size):\n",
    "#     nb_errors = 0\n",
    "\n",
    "#     for b in range(0, test_input.size(0), mini_batch_size):\n",
    "#         #### Modify this based on model outputs ###########\n",
    "#         output = model(test_input.narrow(0, b, mini_batch_size))\n",
    "#         _, predicted_classes = output.max(1)\n",
    "#         ###################################################\n",
    "# #         for k in range(mini_batch_size):\n",
    "# #             if test_target[b + k, predicted_classes[k]] <= 0:\n",
    "# #                 nb_errors = nb_errors + 1\n",
    "\n",
    "#     return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with no weight sharing\n",
    "class Net_noWS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_out = 64\n",
    "        nb_hidden = 32\n",
    "        # X1\n",
    "        self.x1_conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.x1_conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.x1_fc1 = nn.Linear(conv_out, nb_hidden)\n",
    "        self.x1_fc2 = nn.Linear(nb_hidden, 10)\n",
    "        # X2\n",
    "        self.x2_conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.x2_conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.x2_fc1 = nn.Linear(conv_out, nb_hidden)\n",
    "        self.x2_fc2 = nn.Linear(nb_hidden, 10)\n",
    "        # Combine\n",
    "        self.comp_fc = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = 64 \n",
    "        nb_hidden = 32\n",
    "        # X1\n",
    "        x1 = F.relu(F.max_pool2d(self.x1_conv1(x[:, 0].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "        x1 = F.relu(F.max_pool2d(self.x1_conv2(x1), kernel_size=2, stride=2))\n",
    "        x1 = F.relu(self.x1_fc1(x1.view(-1, conv_out)))\n",
    "        x1 = F.relu(self.x1_fc2(x1))\n",
    "        # X2\n",
    "        x2 = F.relu(F.max_pool2d(self.x2_conv1(x[:, 1].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "        x2 = F.relu(F.max_pool2d(self.x2_conv2(x2), kernel_size=2, stride=2))\n",
    "        x2 = F.relu(self.x2_fc1(x2.view(-1, conv_out)))\n",
    "        x2 = F.relu(self.x2_fc2(x2))\n",
    "        # Combine\n",
    "        x = self.comp_fc(torch.cat((x1, x2), 1))\n",
    "        #\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with weight sharing\n",
    "class Net_WS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_out = 64\n",
    "        nb_hidden = 32\n",
    "        # Same for X1 and X2\n",
    "        self.x_conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.x_conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.x_fc1 = nn.Linear(conv_out, nb_hidden)\n",
    "        self.x_fc2 = nn.Linear(nb_hidden, 10)\n",
    "        # Combine\n",
    "        self.comp_fc = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = 64\n",
    "        nb_hidden = 32\n",
    "        # X1\n",
    "        x1 = F.relu(F.max_pool2d(self.x_conv1(x[:, 0].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "        x1 = F.relu(F.max_pool2d(self.x_conv2(x1), kernel_size=2, stride=2))\n",
    "        x1 = F.relu(self.x_fc1(x1.view(-1, conv_out)))\n",
    "        x1 = F.relu(self.x_fc2(x1))\n",
    "        # X2\n",
    "        x2 = F.relu(F.max_pool2d(self.x_conv1(x[:, 1].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "        x2 = F.relu(F.max_pool2d(self.x_conv2(x2), kernel_size=2, stride=2))\n",
    "        x2 = F.relu(self.x_fc1(x2.view(-1, conv_out)))\n",
    "        x2 = F.relu(self.x_fc2(x2))\n",
    "        # Combine\n",
    "        x = self.comp_fc(torch.cat((x1, x2), 1))\n",
    "        #\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, train_classes, mini_batch_size, nb_epochs = 100, criterion = nn.MSELoss(), optimizer = None):\n",
    "    eta = 1e-1\n",
    "    #\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "        #\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            print(output)\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            # train_classes unused\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "            #\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            #\n",
    "            if (optimizer is None):\n",
    "                with torch.no_grad():\n",
    "                    for p in model.parameters():\n",
    "                        p -= eta * p.grad\n",
    "            else:\n",
    "                optimizer.step()\n",
    "        #\n",
    "#         print(e, acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, test_input, test_target, test_classes, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, test_input.size(0), mini_batch_size):\n",
    "        output = model(test_input.narrow(0, b, mini_batch_size))\n",
    "        # test_classes unused\n",
    "        #_, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if output[b + k] != test_target[b + k]:\n",
    "                print('output:', output[b + k])\n",
    "                print('target:', test_target[b + k])\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.7775],\n",
      "        [-8.1099]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.3199],\n",
      "        [-6.9861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-8.7670],\n",
      "        [-5.7075]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-1d1974cb1a3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet_noWS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_train_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_train_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_train_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m#     nb_test_errors = compute_nb_errors(model, ex_test_input, ex_test_target, ex_test_classes, mini_batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-d18a28edaf1f>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_input, train_target, train_classes, mini_batch_size, nb_epochs, criterion, optimizer)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[1;31m# train_classes unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0macc_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m-> 1048\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2693\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2386\u001b[0m         )\n\u001b[0;32m   2387\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2388\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2389\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2390\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 1 is out of bounds."
     ]
    }
   ],
   "source": [
    "ex_train_input = train_input[0:10]\n",
    "ex_train_target = train_target[0:10]\n",
    "ex_train_classes = train_classes[0:10]\n",
    "#\n",
    "ex_test_input = test_input[0:10]\n",
    "ex_test_target = test_target[0:10]\n",
    "ex_test_classes = test_classes[0:10]\n",
    "#\n",
    "mini_batch_size = 2\n",
    "#\n",
    "for k in range(1):\n",
    "    model = Net_noWS()\n",
    "    train_model(model, ex_train_input, ex_train_target, ex_train_classes, mini_batch_size, nb_epochs = 10, criterion = nn.CrossEntropyLoss())\n",
    "#     nb_test_errors = compute_nb_errors(model, ex_test_input, ex_test_target, ex_test_classes, mini_batch_size)\n",
    "#     print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "#                                                       nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# mini_batch_size = 100\n",
    "# #\n",
    "# for k in range(10):\n",
    "#     model = Net_noWS()\n",
    "#     train_model(model, train_input, train_target, train_classes, mini_batch_size)\n",
    "#     nb_test_errors = compute_nb_errors(model, test_input, test_target, test_classes, mini_batch_size)\n",
    "#     print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "#                                                       nb_test_errors, test_input.size(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_pytorch]",
   "language": "python",
   "name": "conda-env-dl_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
