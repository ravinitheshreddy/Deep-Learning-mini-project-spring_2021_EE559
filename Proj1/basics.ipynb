{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "# Prologue\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "N = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train_input sample as Ints:\n",
      " tensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   9,  57, 106,  54,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,  35, 226, 186, 123, 186, 156,   2,   0,   0,   0,   0],\n",
      "         [  0,   0,   0, 156, 132,   0,   0,   4, 197,  21,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,  86, 233, 132,  74, 132, 244,  37,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,  41, 130, 155, 140, 211,  91,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   4, 195,  40,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,  26, 251,  11,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0, 101, 184,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0, 211, 151,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   4, 239,  97,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   2,  93,   3,   0,   0,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0, 116, 227, 240, 227, 209, 122,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0, 140, 140, 140, 140, 227, 252,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,  12, 190, 165,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,  19, 193, 227,  40,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,  44, 224, 209,  15,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,  56, 252,  84,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0, 253,  84,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0, 125, 246,  40,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,  62, 165, 246,  75,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,  12, 212, 223, 165,  46,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print('Example train_input sample as Ints:\\n', train_input[0].int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input: torch.Size([1000, 2, 14, 14])\n",
      "Train target: torch.Size([1000])\n",
      "Train classes: torch.Size([1000, 2])\n",
      "... Same for test too\n",
      "\n",
      "Possible values of train_target: tensor([0, 1])\n",
      "Pairs of classes for all samples:\n",
      " tensor([[9, 3],\n",
      "        [5, 4],\n",
      "        [7, 4],\n",
      "        ...,\n",
      "        [1, 4],\n",
      "        [3, 5],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Reference\n",
    "print('Train input:', train_input.size())\n",
    "print('Train target:', train_target.size())\n",
    "print('Train classes:', train_classes.size())\n",
    "print('... Same for test too\\n')\n",
    "# Target = 1 if digit1<= digit2\n",
    "print('Possible values of train_target:', train_target.unique())\n",
    "print('Pairs of classes for all samples:\\n', train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "# def train_model(model, train_input, train_target, train_classes, mini_batch_size, nb_epochs = 100, criterion = nn.MSELoss(), optimizer = None):\n",
    "#     eta = 1e-1\n",
    "#     #\n",
    "#     for e in range(nb_epochs):\n",
    "#         acc_loss = 0\n",
    "#         # We do this with mini-batches\n",
    "#         for b in range(0, train_input.size(0), mini_batch_size):\n",
    "#             #### Modify this based on model outputs ###########\n",
    "#             output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "#             loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "#             ###################################################\n",
    "#             #acc_loss = acc_loss + loss.item()\n",
    "#             #\n",
    "#             model.zero_grad()\n",
    "#             loss.backward()\n",
    "#             #\n",
    "#             if (optimizer is None):\n",
    "#                 with torch.no_grad():\n",
    "#                     for p in model.parameters():\n",
    "#                         p -= eta * p.grad\n",
    "#             else:\n",
    "#                 optimizer.step()\n",
    "#         #\n",
    "#         print(e, acc_loss)\n",
    "    \n",
    "# def compute_nb_errors(model, test_input, test_target, test_classes, mini_batch_size):\n",
    "#     nb_errors = 0\n",
    "\n",
    "#     for b in range(0, test_input.size(0), mini_batch_size):\n",
    "#         #### Modify this based on model outputs ###########\n",
    "#         output = model(test_input.narrow(0, b, mini_batch_size))\n",
    "#         _, predicted_classes = output.max(1)\n",
    "#         ###################################################\n",
    "# #         for k in range(mini_batch_size):\n",
    "# #             if test_target[b + k, predicted_classes[k]] <= 0:\n",
    "# #                 nb_errors = nb_errors + 1\n",
    "\n",
    "#     return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with no weight sharing\n",
    "class Net_noWS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_out = 64\n",
    "        nb_hidden = 32\n",
    "        # X1\n",
    "        self.x1_conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.x1_conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.x1_fc1 = nn.Linear(conv_out, nb_hidden)\n",
    "        self.x1_fc2 = nn.Linear(nb_hidden, 10)\n",
    "        # X2\n",
    "        self.x2_conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.x2_conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.x2_fc1 = nn.Linear(conv_out, nb_hidden)\n",
    "        self.x2_fc2 = nn.Linear(nb_hidden, 10)\n",
    "        # Combine\n",
    "        self.comp_fc = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = 64 \n",
    "        nb_hidden = 32\n",
    "        # X1\n",
    "        x1 = F.relu(F.max_pool2d(self.x1_conv1(x[:, 0].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "        x1 = F.relu(F.max_pool2d(self.x1_conv2(x1), kernel_size=2, stride=2))\n",
    "        x1 = F.relu(self.x1_fc1(x1.view(-1, conv_out)))\n",
    "        x1 = F.relu(self.x1_fc2(x1))\n",
    "        # X2\n",
    "        x2 = F.relu(F.max_pool2d(self.x2_conv1(x[:, 1].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "        x2 = F.relu(F.max_pool2d(self.x2_conv2(x2), kernel_size=2, stride=2))\n",
    "        x2 = F.relu(self.x2_fc1(x2.view(-1, conv_out)))\n",
    "        x2 = F.relu(self.x2_fc2(x2))\n",
    "        # Combine\n",
    "        x = F.sigmoid(self.comp_fc(torch.cat((x1, x2), 1)))\n",
    "        #\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with weight sharing\n",
    "# class Net_WS(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         conv_out = 64\n",
    "#         nb_hidden = 32\n",
    "#         # Same for X1 and X2\n",
    "#         self.x_conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "#         self.x_conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "#         self.x_fc1 = nn.Linear(conv_out, nb_hidden)\n",
    "#         self.x_fc2 = nn.Linear(nb_hidden, 10)\n",
    "#         # Combine\n",
    "#         self.comp_fc = nn.Linear(20, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         conv_out = 64\n",
    "#         nb_hidden = 32\n",
    "#         # X1\n",
    "#         x1 = F.relu(F.max_pool2d(self.x_conv1(x[:, 0].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "#         x1 = F.relu(F.max_pool2d(self.x_conv2(x1), kernel_size=2, stride=2))\n",
    "#         x1 = F.relu(self.x_fc1(x1.view(-1, conv_out)))\n",
    "#         x1 = F.relu(self.x_fc2(x1))\n",
    "#         # X2\n",
    "#         x2 = F.relu(F.max_pool2d(self.x_conv1(x[:, 1].view(-1, 1, 14, 14)), kernel_size=3, stride=3))\n",
    "#         x2 = F.relu(F.max_pool2d(self.x_conv2(x2), kernel_size=2, stride=2))\n",
    "#         x2 = F.relu(self.x_fc1(x2.view(-1, conv_out)))\n",
    "#         x2 = F.relu(self.x_fc2(x2))\n",
    "#         # Combine\n",
    "#         x = self.comp_fc(torch.cat((x1, x2), 1))\n",
    "#         #\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, train_classes, mini_batch_size, optimizer, criterion, nb_epochs = 100):\n",
    "    eta = 1e-1\n",
    "    #\n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size).float())\n",
    "            # train_classes unused\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, test_input, test_target, test_classes, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, test_input.size(0), mini_batch_size):\n",
    "        output = model(test_input.narrow(0, b, mini_batch_size))\n",
    "        # test_classes unused\n",
    "        expected = test_target.narrow(0, b, mini_batch_size).view(-1, 1)\n",
    "        abs_diff = (expected - output).abs()\n",
    "        for k in range(mini_batch_size):\n",
    "            if (abs_diff[k].item() > 0.5):    # GT or GTE?\n",
    "                nb_errors += 1        \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error Net 60.00% 6/10\n"
     ]
    }
   ],
   "source": [
    "ex_train_input = train_input[0:10]\n",
    "ex_train_target = train_target[0:10]\n",
    "ex_train_classes = train_classes[0:10]\n",
    "#\n",
    "ex_test_input = test_input[0:10]\n",
    "ex_test_target = test_target[0:10]\n",
    "ex_test_classes = test_classes[0:10]\n",
    "#\n",
    "nb_epochs = 10\n",
    "mini_batch_size = 2\n",
    "lr = 1e-1\n",
    "#\n",
    "for k in range(1):\n",
    "    model = Net_noWS()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    train_model(model, ex_train_input, ex_train_target, ex_train_classes, mini_batch_size, optimizer, criterion, nb_epochs)\n",
    "    nb_test_errors = compute_nb_errors(model, ex_test_input, ex_test_target, ex_test_classes, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / ex_test_input.size(0),\n",
    "                                                      nb_test_errors, ex_test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushagra\\anaconda3\\envs\\dl_pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error Net 47.40% 474/1000\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "nb_epochs = 100\n",
    "mini_batch_size = 100\n",
    "lr = 1e-1\n",
    "#\n",
    "for k in range(1):\n",
    "    model = Net_noWS()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    train_model(model, train_input, train_target, train_classes, mini_batch_size, optimizer, criterion, nb_epochs)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, test_classes, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_pytorch]",
   "language": "python",
   "name": "conda-env-dl_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
